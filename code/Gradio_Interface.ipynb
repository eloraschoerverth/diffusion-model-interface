{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4356fe0b",
      "metadata": {
        "id": "4356fe0b"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c9f5b7",
      "metadata": {
        "id": "b7c9f5b7"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U einops datasets matplotlib tqdm torchmetrics torchvision plotly scipy altair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fdbd21",
      "metadata": {
        "id": "21fdbd21"
      },
      "outputs": [],
      "source": [
        "!pip install gradio==v3.13.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe98a87",
      "metadata": {
        "id": "fbe98a87"
      },
      "outputs": [],
      "source": [
        "#External libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy.spatial import distance\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e988311f",
      "metadata": {
        "id": "e988311f"
      },
      "outputs": [],
      "source": [
        "#Local functions\n",
        "from DDPM import GaussianDiffusion, linear_beta_schedule\n",
        "from UNet import Unet\n",
        "from hooks import ObscureChannelHook\n",
        "import interface_helpers\n",
        "import visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2594bf",
      "metadata": {
        "id": "4a2594bf"
      },
      "source": [
        "# 2. Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e00feb1",
      "metadata": {
        "id": "6e00feb1"
      },
      "outputs": [],
      "source": [
        "label_list = ['Bangs', 'Male','Smiling', 'Wearing_Lipstick']\n",
        "block_list = [\"init_conv\", \"downs.0\", \"downs.1\", \"downs.2\", \"downs.3\", \"mid\", \"ups.0\", \"ups.1\", \"ups.2\", \"final_conv\"]\n",
        "layer_list = [\"init_conv\",\n",
        "          \"downs.0.0.ds_conv\",\"downs.0.0.net\",\"downs.0.0.res_conv\",\"downs.0.1.ds_conv\",\"downs.0.1.net\",\"downs.0.1.res_conv\",\"downs.0.2.fn\",\"downs.0.3\",\n",
        "          \"downs.1.0.ds_conv\",\"downs.1.0.net\",\"downs.1.0.res_conv\",\"downs.1.1.ds_conv\",\"downs.1.1.net\",\"downs.1.1.res_conv\",\"downs.1.2.fn\",\"downs.1.3\",\n",
        "          \"downs.2.0.ds_conv\",\"downs.2.0.net\",\"downs.2.0.res_conv\",\"downs.2.1.ds_conv\",\"downs.2.1.net\",\"downs.2.1.res_conv\",\"downs.2.2.fn\",\"downs.2.3\",\n",
        "          \"downs.3.0.ds_conv\",\"downs.3.0.net\",\"downs.3.0.res_conv\",\"downs.3.1.ds_conv\",\"downs.3.1.net\",\"downs.3.1.res_conv\",\"downs.3.2.fn\",\"downs.3.3\",\n",
        "          \"ups.0.0.ds_conv\",\"ups.0.0.net\",\"ups.0.0.res_conv\",\"ups.0.1.ds_conv\",\"ups.0.1.net\",\"ups.0.1.res_conv\",\"ups.0.2.fn\",\"ups.0.3\",\n",
        "          \"ups.1.0.ds_conv\",\"ups.1.0.net\",\"ups.1.0.res_conv\",\"ups.1.1.ds_conv\",\"ups.1.1.net\",\"ups.1.1.res_conv\",\"ups.1.2.fn\",\"ups.1.3\",\n",
        "          \"ups.2.0.ds_conv\",\"ups.2.0.net\",\"ups.2.0.res_conv\",\"ups.2.1.ds_conv\",\"ups.2.1.net\",\"ups.2.1.res_conv\",\"ups.2.2.fn\",\"ups.2.3\",\n",
        "          \"mid_block1.ds_conv\",\"mid_block1.net\",\"mid_block1.res_conv\", \"mid_attn.fn\", \"mid_block2.ds_conv\",\"mid_block2.net\",\"mid_block2.res_conv\",\n",
        "          \"final_conv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ccb004",
      "metadata": {
        "id": "d7ccb004"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace24f0f",
      "metadata": {
        "id": "ace24f0f"
      },
      "outputs": [],
      "source": [
        "#Labels for both 64 and 128 model\n",
        "label_map = {\n",
        "    \"Bangs\": 8,\n",
        "    \"Male\": 4,\n",
        "    \"Smiling\": 2,\n",
        "    \"Wearing_Lipstick\": 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9b4f11",
      "metadata": {
        "id": "ff9b4f11"
      },
      "outputs": [],
      "source": [
        "hooks = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac088b66",
      "metadata": {
        "id": "ac088b66"
      },
      "source": [
        "# 4. Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32dd1fe",
      "metadata": {
        "id": "b32dd1fe"
      },
      "outputs": [],
      "source": [
        "def load_model(model_select):\n",
        "    \"\"\"\n",
        "    Load model and configure DDPM process. As Gradio does not offer an option to return model as a datatype,\n",
        "    we need to declare the model and diffusion as global variable to access from other functions.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    model_select: str\n",
        "        ID of the selected model as a string.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    blocks_select: list[str]: list containing all block IDs of the UNet.\n",
        "    act_unet_image: imageio.Image. Image displaying the model architecture.\n",
        "    grad_unet_image: imageio.Image. Image displaying the model architecture.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    global model, diffusion\n",
        "\n",
        "    timesteps = 1000\n",
        "\n",
        "    if model_select == \"CelebA 128\":\n",
        "        channels, image_size, mode = 3, 128, 'c'\n",
        "        model = Unet(\n",
        "            dim=64,\n",
        "            channels = channels+1,\n",
        "            out_dim = channels,\n",
        "            dim_mults=(1, 2, 4, 8)\n",
        "\n",
        "        )\n",
        "        model.load_state_dict(torch.load('models/128_RGB/model_c_128_rgb_chkpt_32.pth'))\n",
        "        unet_image = imageio.imread('images/unet_128.png')\n",
        "\n",
        "    elif model_select == \"CelebA 64\":\n",
        "        channels, image_size, mode = 3, 64, 'c'\n",
        "        model = Unet(\n",
        "            dim=64,\n",
        "            channels = channels+1,\n",
        "            out_dim = channels,\n",
        "            dim_mults=(1, 2, 4, 8,)\n",
        "\n",
        "        )\n",
        "        model.load_state_dict(torch.load('models/64_RGB_NEW/model_c_64_rgb_chkpt_50.pth'))\n",
        "        unet_image = imageio.imread('images/unet_64.png')\n",
        "    else:\n",
        "        raise AssertionError (\"Please select a model before proceeding\")\n",
        "\n",
        "\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    betas = linear_beta_schedule(timesteps)\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr= 2e-4)\n",
        "\n",
        "    diffusion = GaussianDiffusion(\n",
        "                    model,\n",
        "                    mode = mode,\n",
        "                    image_size = image_size,\n",
        "                    channels = channels,\n",
        "                    timesteps = timesteps,\n",
        "                    loss_type = 'l1',\n",
        "                    betas = betas,\n",
        "                    device = device\n",
        "                    )\n",
        "\n",
        "\n",
        "    return {\n",
        "           blocks_select: gr.update(choices=block_list),\n",
        "           act_unet_image: unet_image,\n",
        "           grad_unet_image: unet_image,\n",
        "           }\n",
        "\n",
        "def configure_interface(blocks_select):\n",
        "    \"\"\"\n",
        "    Configures interface. Updates the selection option of layers depending on selected blocks.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    blocks_select: list[str]\n",
        "        list containing the selection of six blocks by their names\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    l_b0: gr.Checkbox with choices being all layers in the zeroeth block.\n",
        "    l_b1: gr.Checkbox with choices being all layers in the first block.\n",
        "    l_b2: gr.Checkbox with choices being all layers in the second block.\n",
        "    l_b3: gr.Checkbox with choices being all layers in the third block.\n",
        "    l_b4: gr.Checkbox with choices being all layers in the fourth block.\n",
        "    l_b5: gr.Checkbox with choices being all layers in the fifth block.\n",
        "    l_b6: gr.Checkbox with choices being all layers in the sixth block.\n",
        "    mask_layer: gr.Checkbox with choices being all layers in the network.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    assert model is not None, \"Please select a model to proceed\"\n",
        "    assert len(blocks_select) == 6, \"Please select 6 blocks to proceed\"\n",
        "\n",
        "    return {\n",
        "            l_b0: gr.update(choices=[s for s in layer_list if blocks_select[0] in s], visible=True),\n",
        "            l_b1: gr.update(choices=[s for s in layer_list if blocks_select[1] in s], visible=True),\n",
        "            l_b2: gr.update(choices=[s for s in layer_list if blocks_select[2] in s], visible=True),\n",
        "            l_b3: gr.update(choices=[s for s in layer_list if blocks_select[3] in s], visible=True),\n",
        "            l_b4: gr.update(choices=[s for s in layer_list if blocks_select[4] in s], visible=True),\n",
        "            l_b5: gr.update(choices=[s for s in layer_list if blocks_select[5] in s], visible=True),\n",
        "            mask_layer: gr.update(choices=layer_list)\n",
        "           }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2d20b1",
      "metadata": {
        "id": "bd2d20b1"
      },
      "outputs": [],
      "source": [
        "def diffuse(labels, sample_res, l_b0, l_b1, l_b2, l_b3, l_b4, l_b5, random_seed, track_mode, image_mask = None, switch_labels = None, switch_step = None):\n",
        "    \"\"\"\n",
        "        Runs diffusion for given input parameters and returns samples and analysis figures.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        labels (gr.CheckboxGroup): Contains selected labels to condition the model\n",
        "        sampes_res (int): Sampling resoluiton, defining interval of extracting activations/gradient\n",
        "        l_b0,...,l_b5 (str): Name of the selected layer to track.\n",
        "        random_seed (int): Intitial seed for the diffusion process.\n",
        "        track_mode (int): Flag indicating whether activations or gradients should be sampled.\n",
        "        image_mask (gr.Image): Gradio binary mask.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "    \"\"\"\n",
        "\n",
        "    y = sum([label_map[k] for k in labels])\n",
        "    y = torch.tensor([y]).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    layers = [l_b0, l_b1, l_b2, l_b3, l_b4, l_b5]\n",
        "\n",
        "    random_seed = int(random_seed)\n",
        "\n",
        "\n",
        "    sample_steps = [k  for k in np.arange(0,1000)[::-1] if k % sample_res == 0 and k > 0]\n",
        "\n",
        "    if track_mode == 0: #Activations\n",
        "        if switch_labels is not None and switch_step is not None:\n",
        "            s_y = sum([label_map[k] for k in switch_labels])\n",
        "            s_y = torch.tensor([s_y]).to(device)\n",
        "            switch_step = int(switch_step)\n",
        "        analysis_settings = interface_helpers.set_analysis_settings(sample_steps, layers, track_mode = track_mode, mask = None, s_y=s_y, s_t=switch_step)\n",
        "\n",
        "    elif track_mode == 1: #Gradients\n",
        "        mask = torch.from_numpy(np.asarray(image_mask[\"mask\"])[:,:,0:1]).to(device).reshape(1,diffusion.image_size,diffusion.image_size)\n",
        "        analysis_settings = interface_helpers.set_analysis_settings(sample_steps = sample_steps, layers = layers, track_mode = track_mode, mask = mask,s_y=None, s_t=[])\n",
        "\n",
        "    #Sample from DDPM with previously specified settings\n",
        "    samples, gv, acts, grads = diffusion.sample(batch_size=1, random_seed=random_seed, condition = y, analysis=analysis_settings)\n",
        "\n",
        "    #SSIM for every timestep with previous one\n",
        "    ssim_t = [ssim(np.moveaxis(samples[i][0], [0], [2]), np.moveaxis(samples[i-1][0], [0], [2]), multichannel=True) for i in range(1,1000)]\n",
        "\n",
        "    if track_mode == 0: #Activations\n",
        "        return {\n",
        "                    act_out_sample: get_sample_out(samples),\n",
        "                    ssim_fig: visualization.line_plot(values = ssim_t[::-1], x_range = range(1,1000),title='SSIM with previous sample over time', x_title=\"Time Step\", y_title=\"SSIM\"),\n",
        "                    activation_dist_fig: visualization.dist_fig(acts, track_mode, layers, sample_steps),\n",
        "                    activation_step: gr.update(choices=[str(i) for i in sample_steps]),\n",
        "                    activation_layers: layers,\n",
        "                    activations: acts\n",
        "                }\n",
        "\n",
        "    elif track_mode == 1: #Gradients\n",
        "\n",
        "        return {\n",
        "                    grad_out_sample: get_sample_out(samples),\n",
        "                    gradient_step: gr.update(choices=[str(i) for i in sample_steps]),\n",
        "                    gradient_layers: layers,\n",
        "                    ssim_fig:visualization.line_plot(values = ssim_t, x_range = range(1,1000),title='SSIM with previous sample over time', x_title=\"Time Step\", y_title=\"SSIM\"),\n",
        "                    gradient_dist_fig: visualization.dist_fig(grads, track_mode, layers, sample_steps),\n",
        "                    gradient_volume_fig: visualization.gradient_volume_fig(gv, sample_steps, im_shape = diffusion.image_size),\n",
        "                    gradients:grads\n",
        "                }\n",
        "\n",
        "\n",
        "def compare_diffuse(label1, label2, random_seed, sample_res, l_b0, l_b1, l_b2, l_b3, l_b4, l_b5, track_mode, image_mask = None, vs_grad_step= None):\n",
        "    y1 = sum([label_map[k] for k in label1])\n",
        "    y1 = torch.tensor([y1]).to(device)\n",
        "    y2 = sum([label_map[k] for k in label2])\n",
        "    y2 = torch.tensor([y2]).to(device)\n",
        "\n",
        "    layers =  [l_b0,l_b1,l_b2,l_b3,l_b4, l_b5]\n",
        "\n",
        "    sample_steps = [k  for k in np.arange(0,1000)[::-1] if k % sample_res == 0 and k > 0]\n",
        "\n",
        "    if track_mode == 1:#Gradients\n",
        "        print(vs_grad_step)\n",
        "        sample_steps = [int(vs_grad_step)]\n",
        "        assert image_mask is not None, 'Please input a image mask for gradient calculation'\n",
        "        #get gradient mask from input\n",
        "        mask = torch.from_numpy(np.asarray(image_mask[\"mask\"])[:,:,0:1]).to(device).reshape(1,diffusion.image_size,diffusion.image_size)\n",
        "        analysis_settings = interface_helpers.set_analysis_settings(sample_steps = sample_steps, layers = layers, track_mode = track_mode, mask = mask,s_y=None, s_t=[])\n",
        "    else:\n",
        "        analysis_settings = interface_helpers.set_analysis_settings(sample_steps = sample_steps, layers = layers, track_mode=0, mask = None,s_y=None, s_t=[])\n",
        "\n",
        "    #Sample twice from same noise seed\n",
        "    samples1, gv1, acts1, grads1 = diffusion.sample(batch_size=1, random_seed=random_seed, condition = y1, analysis=analysis_settings)\n",
        "    samples2, gv2, acts2, grads2 = diffusion.sample(batch_size=1, random_seed=random_seed, condition = y2, analysis=analysis_settings)\n",
        "\n",
        "\n",
        "    ssim_t = [ssim(samples1[i][0].T, samples2[i][0].T, multichannel=True) for i in range(0,1000)]\n",
        "    ssim_fig = visualization.line_plot(values= ssim_t, x_range = range(0,1000)[::-1],title='SSIM between Label '+str(y1.item())+' and Label '+str(y2.item()), x_title=\"Sample Step\", y_title=\"SSIM\")\n",
        "\n",
        "    if track_mode == 0: #Activations\n",
        "        distance_fig = visualization.vs_dist_fig(acts1, acts2, track_mode, layers, sample_steps, y1, y2)\n",
        "        return get_sample_out(samples1),get_sample_out(samples2), distance_fig, ssim_fig\n",
        "\n",
        "    elif track_mode == 1: #Gradients\n",
        "        img_vol1_fig = visualization.gradient_volume_fig(gv1, str(vs_grad_step), diffusion.image_size)\n",
        "        img_vol2_fig = visualization.gradient_volume_fig(gv2, str(vs_grad_step), diffusion.image_size)\n",
        "        return get_sample_out(samples1), get_sample_out(samples2), ssim_fig, img_vol1_fig, img_vol2_fig\n",
        "\n",
        "    elif track_mode == 2: # Attention\n",
        "        map1 = interface_helpers.interpolate_attention_map(acts1, sample_steps)\n",
        "        map2 = interface_helpers.interpolate_attention_map(acts2, sample_steps)\n",
        "\n",
        "        attn_dists = [np.linalg.norm(map1[step] - map2[step]) for step in np.arange(len(map1))]\n",
        "\n",
        "        attn_dist_fig = visualization.scatter_plot(x=sample_steps,y=attn_dists, title=\"Euclidean Distance between Attention Maps of Label \"+str(y1.item())+\" and Label \"+str(y2.item()), x_title=\"Timestep\", y_title=\"Euclidean Distance\")\n",
        "\n",
        "        attn_map1_fig = visualization.img_plot(values=np.stack(map1, axis=0), slider_title=\"Timestep\",color=\"Inferno\", title=\"Attention Map Label \"+str(y1.item()))\n",
        "\n",
        "        attn_map2_fig = visualization.img_plot(values=np.stack(map2, axis=0), slider_title=\"Timestep\",color=\"Inferno\", title=\"Attention Map Label \"+str(y2.item()))\n",
        "\n",
        "        return get_sample_out(samples1), get_sample_out(samples2), ssim_fig, attn_map1_fig, attn_map2_fig, attn_dist_fig\n",
        "\n",
        "\n",
        "def generate_activation_maps(ts, signal, layers, image_mask=None):\n",
        "    ts  = int(ts) #read timestep and convert to int\n",
        "\n",
        "    fig_dic = {}#initialize emtpy dictionaries for figures and max channels\n",
        "\n",
        "    for i in range(len(layers)):\n",
        "\n",
        "        values = signal[str(ts)][layers[i]][0,:,:,:]\n",
        "        values = (values-values.min())/(values.max()-values.min())\n",
        "        fig_dic[str(i)] = visualization.img_plot(values, slider_title=\"Channel\", color=\"Inferno\", title=layers[i])\n",
        "\n",
        "    print(\"done\")\n",
        "    fig_dic[\"0\"].show()\n",
        "    fig_dic[\"1\"].show()\n",
        "    fig_dic[\"2\"].show()\n",
        "    fig_dic[\"3\"].show()\n",
        "    fig_dic[\"4\"].show()\n",
        "    fig_dic[\"5\"].show()\n",
        "    return fig_dic[\"0\"], fig_dic[\"1\"], fig_dic[\"2\"], fig_dic[\"3\"], fig_dic[\"4\"], fig_dic[\"5\"]\n",
        "\n",
        "def generate_gradient_maps(ts, signal, layers):\n",
        "    ts  = int(ts) #read timestep and convert to int\n",
        "\n",
        "    fig_dic = {}#initialize emtpy dictionaries for figures and max channels\n",
        "\n",
        "    for i in range(len(layers)):\n",
        "        values = np.stack(signal[str(ts)][layers[i]], axis=0).sum(axis=0)[0]\n",
        "        values = (values-values.min())/(values.max()-values.min())\n",
        "        fig_dic[str(i)] = visualization.img_plot(values,slider_title=\"Channel\", color=\"Ice\", title=layers[i])\n",
        "\n",
        "    print(\"done\")\n",
        "    fig_dic[\"0\"].show()\n",
        "    fig_dic[\"1\"].show()\n",
        "    fig_dic[\"2\"].show()\n",
        "    fig_dic[\"3\"].show()\n",
        "    fig_dic[\"4\"].show()\n",
        "    fig_dic[\"5\"].show()\n",
        "\n",
        "    return fig_dic[\"0\"], fig_dic[\"1\"], fig_dic[\"2\"], fig_dic[\"3\"], fig_dic[\"4\"], fig_dic[\"5\"]\n",
        "\n",
        "\n",
        "def calculate_max_channels(ts, signal, layers, mode, image_mask = None):\n",
        "    ts  = int(ts)\n",
        "    mc_dic = {}\n",
        "\n",
        "    for i in range(len(layers)):\n",
        "        if mode == 0: #activations\n",
        "            data = signal[str(ts)][layers[i]][0,:,:,:]\n",
        "            data = (data-data.min())/(data.max()-data.min())\n",
        "\n",
        "        elif mode == 1: #gradients\n",
        "            data = np.stack(signal[str(ts)][layers[i]], axis=0).sum(axis=0)[0]\n",
        "            data = (data-data.min())/(data.max()-data.min())\n",
        "\n",
        "        mc_dic[str(i)] = interface_helpers.max_sum_channel(data = data, img_mask=image_mask)\n",
        "\n",
        "    return mc_dic[\"0\"], mc_dic[\"1\"], mc_dic[\"2\"], mc_dic[\"3\"], mc_dic[\"4\"], mc_dic[\"5\"]\n",
        "\n",
        "def set_msk_ch(layer_id, channel):\n",
        "\n",
        "    layer = dict([*model.named_modules()])[layer_id]\n",
        "    hooks[layer_id + str(channel)] =  ObscureChannelHook(layer, int(channel))\n",
        "\n",
        "    print(\"Hook attached to layer\", layer_id, \" at channel\", int(channel))\n",
        "\n",
        "def remove_msk_ch(layer_id, channel):\n",
        "    hooks[layer_id + str(channel)].close()\n",
        "\n",
        "    print(\"Hook removed from layer\", layer_id, \" at channel\", int(channel))\n",
        "\n",
        "def get_sample_out(samples):\n",
        "    #Plot every 100th samples, normalize it and swap axes to simplify plot later on\n",
        "    sample_out = [interface_helpers.normalize(i) for i in np.vstack(samples)[::100,:,:,:][1:].swapaxes(1,2).swapaxes(2,3)]\n",
        "    #Append last sample at step 999\n",
        "    sample_out.append(interface_helpers.normalize(samples[999][0,:,:,:].swapaxes(0,1).swapaxes(1,2)))\n",
        "\n",
        "    return sample_out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933a1b1f",
      "metadata": {
        "id": "933a1b1f"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "      \"\"\"\n",
        "      # <center> XAI Diffusion Interface </center>\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "######################################### Settings ########################################################\n",
        "    with gr.Row():\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "                                #### ‚åõ Load Model:\n",
        "                            \"\"\")\n",
        "    with gr.Row():\n",
        "        model_select = gr.Dropdown(choices=[\"CelebA 64\", \"CelebA 128\"],label=\"Which model would you like to use?\")\n",
        "        btn_model_select = gr.Button(\"Select Model\")\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"\"\"\n",
        "                            #### üß± Select UNet blocks to analyze:\n",
        "                            \"\"\")\n",
        "    with gr.Row():\n",
        "        blocks_select = gr.CheckboxGroup(choices=[\"\"], label=\"Pick 6 blocks of the UNet to analyze\")\n",
        "        btn_blocks_select = gr.Button(\"Select Blocks\")\n",
        "\n",
        "    #states to store activations and gradients\n",
        "    activations, gradients  = gr.State([]), gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"\"\"\n",
        "                            #### üì£ Set initial noise, sampling resolution and labels:\n",
        "                            \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            sample_res = gr.Slider(minimum=0, maximum= 998, label=\"Sample resolution\")\n",
        "        with gr.Column():\n",
        "            random_seed = gr.Number(value=67654654, label=\"Initial Random Noise\", precision=0)\n",
        "        with gr.Column():\n",
        "            diffusion_labels = gr.CheckboxGroup(choices=label_list, label=\"Labels you want to condition on\")\n",
        "\n",
        "    with gr.Row():# as set_2:\n",
        "        gr.Markdown(\"\"\"\n",
        "                    #### ‚õèÔ∏è Define Image Mask for gradient calculation and pick layers to extract activations/gradients from:\n",
        "                            \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "\n",
        "            image_mask = gr.Image(\n",
        "                        source = \"upload\",\n",
        "                        tool=\"sketch\",\n",
        "                        image_mode=\"L\",\n",
        "                        label=\"Input Mask for gradient calculation\",\n",
        "                        type=\"pil\"\n",
        "                    ).style(height=220)\n",
        "        with gr.Column():\n",
        "            l_b0 = gr.Dropdown(choices=[\"\"], label=\"Pick layer in Block 1\")\n",
        "            l_b1 = gr.Dropdown(choices=[\"\"], label=\"Pick layer in Block 2\")\n",
        "            l_b2 = gr.Dropdown(choices=[\"\"], label=\"Pick layer in Block 3\")\n",
        "        with gr.Column():\n",
        "            l_b5 = gr.Dropdown(choices=[\"\"], label=\"Pick layer in Block 6\")\n",
        "            l_b4 = gr.Dropdown(choices=[\"\"],label=\"Pick layer in Block 5\")\n",
        "            l_b3 = gr.Dropdown(choices=[\"\"], label=\"Pick layer in Block 4\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"\"\"\n",
        "                            #### üò∑ Channel Masking:\n",
        "                        \"\"\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    mask_layer = gr.Dropdown(label=\"Select the layer\")\n",
        "                with gr.Column():\n",
        "                    mask_channel = gr.Number(label=\"Input the channel\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    btn_msk_channel = gr.Button(\"Attach mask to channel\")\n",
        "                with gr.Column():\n",
        "                    btn_unmsk_channel = gr.Button(\"Remove mask from channel\")\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"\"\"\n",
        "                            #### üîÑ Label Switch:\n",
        "                        \"\"\")\n",
        "            with gr.Row():\n",
        "                with gr.Column(min_width=300):\n",
        "                    switch_labels = gr.CheckboxGroup(choices=label_list, label=\"Label to switch to\")\n",
        "                with gr.Column():\n",
        "                    switch_step = gr.Number(label=\"Timestep of Switch\")\n",
        "\n",
        "######################################### ACTIVATIONS ########################################################\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Tab(\"Activations\"):\n",
        "            activation_layers = gr.State([])\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    btn_diffuse_act = gr.Button(\"1. Sample with Activations\")\n",
        "            with gr.Row():\n",
        "                act_out_sample = gr.Gallery(\n",
        "                    label=\"Every 100th sample\"\n",
        "                ).style(grid=[10], height=\"auto\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig0 = gr.Plot(label=\"Activations Block 1\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig1 = gr.Plot(label=\"Activations Block 2\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig2 = gr.Plot(label=\"Activations Block 3\")\n",
        "\n",
        "                with gr.Column(min_width=800):\n",
        "                    with gr.Row():\n",
        "                        act_unet_image = gr.Image(label=\"UNet\")\n",
        "                    with gr.Row():\n",
        "                            activation_step = gr.Radio(choices=[0], label=\"Select Timestep for Activations\")\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            mc0 = gr.Number(value=0,label=\"Max Channel Block 1\")\n",
        "                            mc1 = gr.Number(value=0,label=\"Max Channel Block 2\")\n",
        "                            mc2 = gr.Number(value=0,label=\"Max Channel Block 3\")\n",
        "                        with gr.Column():\n",
        "                            mc5 = gr.Number(value=0,label=\"Max Channel Block 6\")\n",
        "                            mc4 = gr.Number(value=0,label=\"Max Channel Block 5\")\n",
        "                            mc3 = gr.Number(value=0,label=\"Max Channel Block 4\")\n",
        "                        with gr.Row():\n",
        "                            acts_btn = gr.Button(\"2. Compute Activation Maps\")\n",
        "                            a_cnl_btn = gr.Button(\"3. Calculate Max Channels\")\n",
        "\n",
        "                with gr.Column():\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig5 = gr.Plot(label=\"Activations Block 6\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig4 = gr.Plot(label=\"Activations Block 5\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig3 = gr.Plot(label=\"Activations Block 4\")\n",
        "\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ssim_fig = gr.Plot(label=\"SSIM between sample and previous one over time\")\n",
        "                with gr.Column(min_width=700):\n",
        "                    activation_dist_fig = gr.Plot(label=\"Euclidean Distance between activation maps over time\")\n",
        "\n",
        "\n",
        "    ######################################### GRADIENT ########################################################\n",
        "\n",
        "        with gr.Tab(\"Gradient\"):\n",
        "            gradient_layers = gr.State([])\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    btn_diffuse_grad = gr.Button(\"1. Sample with Gradient\")\n",
        "\n",
        "            with gr.Row():\n",
        "\n",
        "                grad_out_sample = gr.Gallery(\n",
        "                        label=\"Every 100th sample\"\n",
        "                    ).style(grid=[10], height=\"auto\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig7 = gr.Plot(label=\"Gradient Block 0\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig8 = gr.Plot(label=\"Gradient Block 1\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig9 = gr.Plot(label=\"Gradient Block 2\")\n",
        "\n",
        "                with gr.Column(min_width=700):\n",
        "                    with gr.Row():\n",
        "                        grad_unet_image = gr.Image(label=\"UNet\")\n",
        "                    with gr.Row():\n",
        "                        gradient_step = gr.Radio(choices=[0], label=\"Select Timestep for Gradients\")\n",
        "                    with gr.Row():\n",
        "                        gr_btn = gr.Button(\"2. Get Gradient Maps\")\n",
        "                        gr_cnl_btn = gr.Button(\"3. Calculate Max Channels\")\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            mc7 = gr.Number(value=0,label=\"Max Channel Downs 0\")\n",
        "                            mc8 = gr.Number(value=0,label=\"Max Channel Downs 1\")\n",
        "                            mc9 = gr.Number(value=0,label=\"Max Channel Downs 2\")\n",
        "                        with gr.Column():\n",
        "                            mc12 = gr.Number(value=0,label=\"Max Channel Ups 1\")\n",
        "                            mc11 = gr.Number(value=0,label=\"Max Channel Ups 0\")\n",
        "                            mc10 = gr.Number(value=0,label=\"Max Channel Mid\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        fig12 = gr.Plot(label=\"Gradient Block 5\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig11 = gr.Plot(label=\"Gradient Block 4\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        fig10 = gr.Plot(label=\"Gradient Block 3\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(min_width=700):\n",
        "                    gradient_dist_fig = gr.Plot(label=\"Euclidean Distance between gradient timesteps\")\n",
        "\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    gradient_volume_fig = gr.Plot(label=\"Image Channel Gradient\")\n",
        "\n",
        "\n",
        "    ######################################### MUTUAL INFO ##########################################################\n",
        "\n",
        "        with gr.Tab(\"Compare samples\"):\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    vs_label_1 = gr.CheckboxGroup(label_list, label=\"First Sample Label\")\n",
        "                with gr.Column():\n",
        "                    vs_label_2 = gr.CheckboxGroup(label_list, label=\"Second Sample Label\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    vs_sample_1 = gr.Gallery(\n",
        "                        label=\"Every 100th sample\"\n",
        "                    ).style(grid=[4], height=\"auto\")\n",
        "                with gr.Column(min_width=700):\n",
        "                    vs_ssim_plot = gr.Plot(label=\"SSIM between samples\")\n",
        "                with gr.Column():\n",
        "                    vs_sample_2 = gr.Gallery(\n",
        "                        label=\"Every 100th sample\"\n",
        "                    ).style(grid=[4], height=\"auto\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Tab(\"Activation Distance\"):\n",
        "                    gr.Markdown(\"\"\"\n",
        "                                    ## <center> Activation Maps Distance</center>\n",
        "\n",
        "                                \"\"\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            vs_act_plot = gr.Plot(label=\"L2 distance between activations\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        btn_vs_act = gr.Button(\"Calculate activation distance\")\n",
        "\n",
        "                with gr.Tab(\"Gradient Volumes\"):\n",
        "                    with gr.Row():\n",
        "                        gr.Markdown(\"\"\"\n",
        "                                        ## <center>Compare Gradient Volumes at one timestep</center>\n",
        "\n",
        "                                    \"\"\")\n",
        "                    with gr.Row():\n",
        "                        vs_grad_step = gr.Number(value=500, label=\"Sample Timestep\", precision = 0)\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            img_vol1_fig = gr.Plot(label=\"Gradient Volume Sample 1\")\n",
        "                        with gr.Column():\n",
        "                            img_vol2_fig = gr.Plot(label=\"Gradient Volume Sample 2\")\n",
        "                    with gr.Row():\n",
        "                        btn_vs_grad = gr.Button(\"Calculate gradient volumes\")\n",
        "\n",
        "                with gr.Tab(\"Attention Map\"):\n",
        "                    with gr.Row():\n",
        "                        gr.Markdown(\"\"\"\n",
        "                                        ## <center>Attention Maps Distance</center>\n",
        "\n",
        "                                        <center>To compute the attention map, you need activations from all attention layers, e.g. layer ending in fn.to_out</center>\n",
        "                                    \"\"\")\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            attn_map1 = gr.Plot(label=\"Attention Map 1\")\n",
        "                        with gr.Column(min_width=700):\n",
        "                            attn_dist_fig = gr.Plot(label=\"Distance between Attention Maps\")\n",
        "                        with gr.Column():\n",
        "                            attn_map2 = gr.Plot(label=\"Attention Map 2\")\n",
        "                    with gr.Row():\n",
        "                        btn_vs_attn = gr.Button(\"Calculate Attention Distance\")\n",
        "\n",
        "\n",
        "    act_mode = gr.State(0)\n",
        "    grad_mode = gr.State(1)\n",
        "    attn_mode = gr.State(2)\n",
        "\n",
        "\n",
        "    #Individual Trajectories\n",
        "    btn_diffuse_act.click(diffuse,\n",
        "                          inputs=[diffusion_labels,sample_res, l_b0,l_b1,l_b2,l_b3,l_b4,l_b5, random_seed, act_mode, image_mask, switch_labels,switch_step],\n",
        "                          outputs=[act_out_sample, ssim_fig, activation_dist_fig, activation_step, activation_layers, activations])\n",
        "\n",
        "\n",
        "\n",
        "    btn_diffuse_grad.click(diffuse,\n",
        "                         inputs=[diffusion_labels,sample_res,l_b0,l_b1,l_b2,l_b3,l_b4,l_b5, random_seed, grad_mode, image_mask],\n",
        "                         outputs=[grad_out_sample, gradient_step, gradient_layers, ssim_fig, gradient_dist_fig,  gradient_volume_fig, gradients])\n",
        "\n",
        "\n",
        "    btn_vs_act.click(compare_diffuse,\n",
        "                     inputs=[vs_label_1, vs_label_2, random_seed,sample_res, l_b0, l_b1, l_b2, l_b3, l_b5, l_b4, act_mode],\n",
        "                     outputs=[vs_sample_1, vs_sample_2, vs_act_plot, vs_ssim_plot])\n",
        "\n",
        "    btn_vs_grad.click(compare_diffuse,\n",
        "                      inputs=[vs_label_1, vs_label_2, random_seed,sample_res, l_b0, l_b1, l_b2, l_b3, l_b5, l_b4, grad_mode, image_mask, vs_grad_step],\n",
        "                      outputs=[vs_sample_1, vs_sample_2, vs_ssim_plot,img_vol1_fig, img_vol2_fig])\n",
        "\n",
        "    btn_vs_attn.click(compare_diffuse, inputs=[vs_label_1, vs_label_2, random_seed, sample_res, l_b0, l_b1, l_b2, l_b3, l_b5, l_b4, attn_mode],\n",
        "                   outputs=[vs_sample_1, vs_sample_2, vs_ssim_plot, attn_map1, attn_map2, attn_dist_fig])\n",
        "\n",
        "    #Channel Masking\n",
        "\n",
        "    btn_msk_channel.click(set_msk_ch,\n",
        "                          inputs=[mask_layer, mask_channel])\n",
        "\n",
        "    btn_unmsk_channel.click(remove_msk_ch,\n",
        "                           inputs=[mask_layer, mask_channel])\n",
        "\n",
        "    #Maps Generation\n",
        "\n",
        "    acts_btn.click(generate_activation_maps,\n",
        "                   inputs=[activation_step, activations, activation_layers, image_mask],\n",
        "                   outputs=[fig0, fig1, fig2, fig3, fig4, fig5])\n",
        "\n",
        "    gr_btn.click(generate_gradient_maps,\n",
        "                 inputs=[gradient_step, gradients, gradient_layers],\n",
        "                 outputs=[fig7, fig8, fig9, fig10, fig11, fig12])\n",
        "\n",
        "    #Max Channel\n",
        "\n",
        "    a_cnl_btn.click(calculate_max_channels,\n",
        "                    inputs=[activation_step, activations, activation_layers, act_mode, image_mask],\n",
        "                   outputs=[mc0, mc1, mc2, mc3, mc4, mc5])\n",
        "\n",
        "\n",
        "\n",
        "    gr_cnl_btn.click(calculate_max_channels,\n",
        "                    inputs=[gradient_step, gradients, gradient_layers, grad_mode],\n",
        "                    outputs=[mc7, mc8, mc9, mc10, mc11, mc12])\n",
        "\n",
        "    #Configure Interface\n",
        "    btn_model_select.click(load_model,\n",
        "                   inputs=[model_select],\n",
        "                   outputs=[blocks_select, act_unet_image, grad_unet_image])\n",
        "\n",
        "    btn_blocks_select.click(configure_interface,\n",
        "                           inputs=[blocks_select],\n",
        "                           outputs=[l_b0,l_b1,l_b2,l_b3,l_b4,l_b5,mask_layer])\n",
        "\n",
        "\n",
        "demo.launch(debug=False, share=True, show_error=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_mxnet_latest_p37",
      "language": "python",
      "name": "conda_mxnet_latest_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}